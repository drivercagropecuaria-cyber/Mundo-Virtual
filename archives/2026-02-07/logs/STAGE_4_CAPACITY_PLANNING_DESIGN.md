# ğŸ“Š STAGE 4: Capacity Planning - Design & Roadmap
## Mundo Virtual Villa Canabrava - Sprint 3

**Data de Planejamento:** 6 FEB 2026 18:30 UTC-3  
**Timeline de ExecuÃ§Ã£o:** 7-10 FEB 2026 (4 dias Ãºteis)  
**Status:** ğŸ”µ EM DESIGN (APROVAÃ‡ÃƒO PENDENTE)  

---

## ğŸ“‹ EXECUTIVE SUMMARY

### Objetivos de STAGE 4

STAGE 4 valida a viabilidade de produÃ§Ã£o das 5 otimizaÃ§Ãµes (OPT1-OPT5) atravÃ©s de **benchmarking rigoroso** em 6 eixos estratÃ©gicos:

1. **Performance das otimizaÃ§Ãµes** - Quantificar ganhos latÃªncia/throughput/percentis
2. **EficiÃªncia de particionamento** - Validar cobertura de partiÃ§Ãµes e pruning hit rate
3. **Performance de refresh MVs** - Garantir <5 min de refresh sem impacto em produÃ§Ã£o
4. **Capacidade RPC Search** - Testar 1000 calls simultÃ¢neas com P95 <200ms
5. **Overhead de auto-partition** - Validar trigger <2% CPU durante peak hours
6. **Sizing de recursos** - Estabelecer CPU/Memory/Storage/Network para 3 cenÃ¡rios

**Resultado Final:** DocumentaÃ§Ã£o completa para sign-off de produÃ§Ã£o com Go/No-Go decision clara.

---

### Timeline de ExecuÃ§Ã£o

| Dia | Data | Foco Principal | Horas | Status |
|-----|------|-----------------|-------|--------|
| **Dia 1** | Feb 7 | Benchmarking Setup + Baseline | 8h | ğŸ”µ PLANEJADO |
| **Dia 2** | Feb 8 | OPT1-5 Performance Tests | 8h | ğŸ”µ PLANEJADO |
| **Dia 3** | Feb 9 | RPC Deep Dive + Auto-Partition Stress | 8h | ğŸ”µ PLANEJADO |
| **Dia 4** | Feb 10 | Resource Estimation + Sign-off | 8h | ğŸ”µ PLANEJADO |

---

### Equipe & Responsabilidades

| Agente | Responsabilidade | Eixo(s) |
|--------|------------------|---------|
| **Agent-DB** | OPT1-2 benchmarking + partitioning metrics | Eixo 1, 2, 5 |
| **Cache** | OPT5 MV refresh + scheduling validation | Eixo 3 |
| **Observability** | Grafana dashboards + Prometheus metrics | Todos |
| **Docs** | ConsolidaÃ§Ã£o de resultados + sign-off documentation | Todos |
| **Executor/Orquestrador** | CoordenaÃ§Ã£o diÃ¡ria + escalaÃ§Ã£o L1/L2/L3 | Governance |

---

### Critical Success Factors

| # | CSF | MÃ©trica de Sucesso | Owner |
|---|-----|-------------------|-------|
| 1 | Baseline coletado | 100% das 6 mÃ©tricas com dados T0 | Observability |
| 2 | OPT1-5 testadas em paralelo | Resultados comparativos 5 otimizaÃ§Ãµes | Agent-DB |
| 3 | RPC validado sob carga | P95 <200ms com 1000 calls simultÃ¢neas | Cache |
| 4 | Auto-partition testado | Overhead <2% CPU durante trigger ativaÃ§Ã£o | Agent-DB |
| 5 | Recursos estimados | 3 cenÃ¡rios documentados (S/M/L) | Docs |
| 6 | Sign-off completo | Checklist 6/6 passando + Go decision | Executor |

---

## ğŸ—“ï¸ ROADMAP: 4 Dias (FEB 7-10)

### âš™ï¸ Dia 1: FEB 7 - Benchmarking Setup + Baseline Collection

**Objetivo:** Estabelecer ambiente de teste e coletar mÃ©tricas baseline (sem otimizaÃ§Ãµes)

#### ManhÃ£ (09:00-12:00 UTC)

**09:00 - KICKOFF & Ambiente Setup**
- Daily Sync #1 (todos os agentes, 30 min)
- Verificar Grafana + Prometheus rodando
- Validar dataset: 251 GIS features carregadas
- Confirmar 100+ queries de teste disponÃ­veis

**10:00 - Baseline Metrics Collection (Sem OPT1-5)**
- Agent-DB: Executar suite de testes contra banco ORIGINAL (sem otimizaÃ§Ãµes)
- Coletar:
  - Query latency (p50, p95, p99) para cada query tipo
  - Throughput (QPS) mÃ¡ximo sustentÃ¡vel
  - CPU/Memory/IO utilization durante testes
  - Partition scan count (baseline, sem particionamento)
- Observability: Exportar mÃ©tricas para Prometheus (tag: baseline-feb7)

**11:30 - Checkpoint Morning**
- Morning standup de 30 min
- Validar se baseline foi coletada 100%
- Documentar blockers (se houver)

#### Tarde (12:00-17:00 UTC)

**12:00 - RPC Search Baseline (Sem OPT3)**
- Cache: Executar 100 RPC search calls sequenciais (sem load)
- Medir: latÃªncia p50/p95/p99, throughput base
- Documentar funÃ§Ã£o search_catalogo() performance

**14:00 - Auto-Partition Baseline (Sem OPT4)**
- Agent-DB: Verificar trigger overhead sem dados 2029+
- Medir CPU/Memory idle de auto-partition structures
- Estabelecer baseline <0.1% CPU overhead

**15:00 - MV Refresh Baseline (Sem OPT5)**
- Cache: Medir tempo de cÃ¡lculo dinÃ¢mico sem MVs
- Baseline de CPU/IO durante query de bounds complexas
- Documentar expected cost de materializaÃ§Ã£o

**16:00 - ConsolidaÃ§Ã£o & Armazenamento**
- Docs: Consolidar todos os nÃºmeros baseline em `METRICS_BASELINE_FEB7.json`
- Observability: Salvar dashboards Grafana com baseline snapshot
- Validar: 6 mÃ©tricas baseline documentadas

**17:00 - Evening Status**
- Status report de 30 min (Executor/Orquestrador)
- RevisÃ£o: Todos os dados baseline foram coletados?
- Next day readiness

---

### ğŸš€ Dia 2: FEB 8 - OPT1-OPT5 Performance Tests

**Objetivo:** Executar benchmarks de cada otimizaÃ§Ã£o e medir performance gains

#### ManhÃ£ (09:00-12:00 UTC)

**09:00 - Daily Sync #2**
- Briefing rÃ¡pido (baseline finalizado?)
- Plan para testes paralelos de OPT1-5
- Timeout policy: Qualquer teste >60s cancela e documenta

**10:00 - OPT1 & OPT2 Benchmarking (Agent-DB - Paralelo)**

**OPT1: Temporal Partitioning Benchmark**
- Ativar OPT1 em ambiente de teste (catalogo_geometrias_particionada)
- Executar 100+ queries com filtros temporais (2026-2028)
- Medir:
  - Query latency vs baseline: target >40% reduÃ§Ã£o
  - Partition pruning hit rate: target >95%
  - Index scan count: target <5 partiÃ§Ãµes por query
  - EXPLAIN ANALYZE para 10 queries representativas
- Grafana: Plot latency comparison (baseline vs OPT1)

**OPT2: Columnar Storage Benchmark**
- Ativar OPT2 (catalogo_bounds_cache + mv_catalogo_geometrias_stats)
- Executar 50 bounds queries e 50 geometry stats queries
- Medir:
  - Cache hit rate: target >95%
  - Latency improvement vs dynamic calc: target >60%
  - Storage compression: columnar format size vs original
  - Materialized view refresh time: time to refresh all MVs

**11:30 - Checkpoint & Intermediate Results**
- Agent-DB: Parar e consolidar OPT1/OPT2 resultados
- Observability: Conferir grÃ¡ficos Grafana
- Continue ou escalate?

#### Tarde (12:00-17:00 UTC)

**13:00 - OPT3, OPT4, OPT5 Benchmarking**

**OPT3: Indexed Views + RPC Search Benchmark**
- Ativar mv_catalogo_search_indexed + search_catalogo_indexed() RPC
- Executar 100 RPC search calls com queries variadas
- Medir:
  - RPC latency p50/p95/p99: target p95 <100ms
  - Throughput (RPC/s): baseline measurement
  - Full-text search performance: indexed vs scan
  - Relevance ranking quality (qualitative)

**OPT4: Auto-Partition Creation Overhead**
- Validar trigger auto_create_partition_for_year()
- Medir overhead em operaÃ§Ãµes INSERT:
  - Extra CPU cycles: target <2% overhead
  - Lock contention: target zero lock waits
  - Index creation time para novo ano: <5 segundos
- Teste: Simular INSERT para 2029 (trigger ativaÃ§Ã£o)

**OPT5: MV Refresh Scheduling Performance**
- Validar pg_cron agendamentos
- Executar refresh_all_materialized_views() manualmente
- Medir:
  - Refresh time: target <5 minutos para MVs
  - Peak CPU durante refresh: target <20% CPU
  - Impact em queries concorrentes: target <5% latency increase
  - Cron job accuracy: verificar logs de execuÃ§Ã£o

**16:00 - ConsolidaÃ§Ã£o de Resultados**
- Docs: Compilar comparativo 5 otimizaÃ§Ãµes em tabela
- Formato: Baseline vs OPT1 vs OPT2 vs OPT3 vs OPT4 vs OPT5
- CÃ¡lcular % improvement para cada mÃ©trica

**17:00 - Evening Status**
- Status: OPT1-5 todos testados?
- Resultados confirmam 36.6% improvement de STAGE 2?
- Blockers para Dia 3?

---

### ğŸ¯ Dia 3: FEB 9 - RPC Load Test + Auto-Partition Stress + Partitioning Deep Dive

**Objetivo:** Validar cenÃ¡rios extremos e eficiÃªncia de particionamento

#### ManhÃ£ (09:00-12:00 UTC)

**09:00 - Daily Sync #3**
- Quick check: OPT1-5 resultados OK?
- Plan para testes de carga + stress
- Team readiness para cenÃ¡rios extremos

**10:00 - RPC Search Load Test (1000 Concurrent Calls)**

Cache executa teste de capacidade RPC:
- Load test tool: Apache JMeter ou similiar
- Config: 1000 threads paralelos, 5 min duration
- Queries: Mix variado (search texto, filtro tipo, bounds queries)
- Medir:
  - P95 latency: target <200ms
  - P99 latency: target <500ms
  - Throughput: target >50 RPC/s
  - Error rate: target 0%
  - Database connection pool stress: target no overflow

**CenÃ¡rio de Sobrecarga:** 2000 threads (double load)
- P95 latency degradation: target <3x vs 1000 threads
- Identify breaking point onde sistema falha

**11:30 - RPC Results Review**
- Cache: AnÃ¡lise de resultados
- Capacity calculation: Quantos usuÃ¡rios simultÃ¢neos suportados?
- RecomendaÃ§Ãµes de connection pool sizing

#### Tarde (12:00-17:00 UTC)

**13:00 - Auto-Partition Stress Test (2029+ Growth Simulation)**

Agent-DB executa stress test de trigger auto-partition:
- SimulaÃ§Ã£o: Inserir 10,000 registros com datas 2029-2035
- Monitor durante inserts:
  - CPU utilization por trigger execution
  - Lock contention (pg_stat_locks)
  - Index creation overhead (pg_stat_index_usage)
- Medir overhead em INSERT latency:
  - Target: <2% slowdown vs sem trigger

**OPT4 Trigger Validation:**
- Verificar novo ano partitions criadas automaticamente
- Validar Ã­ndices criados em cada partiÃ§Ã£o:
  - GIST em geometry âœ“
  - Index em created_at DESC âœ“
  - Composite em (catalogo_id, is_valid) âœ“
- Test trigger failure scenario (se partiÃ§Ã£o jÃ¡ existe)

**14:30 - Partitioning Efficiency Deep Dive**

Agent-DB analisa OPT1 + OPT4 eficiÃªncia:

**MÃ©tricas de Partitioning:**
- Partition coverage: % de queries que usam partition pruning
- Scan efficiency: Average partiÃ§Ãµes scannadas por query (target <5)
- Index efficiency: GIST index hit rate (target >90%)
- Partition distribution: Data uniformemente distribuÃ­do nos anos?

**EXPLAIN ANALYZE de 20 Queries CrÃ­ticas:**
- Para cada query: Extrair execution plan
- Validar que estÃ¡ usando partitions corretamente
- Documentar any queries que nÃ£o aproveitam partitions
- RecomendaÃ§Ãµes de indexing (se houver)

**Dashboard de Partition Health:**
- Grafana dashboard mostrando:
  - Partition sizes (2026, 2027, 2028)
  - Query scan count distribution
  - Index usage by partition
  - Partition pruning hit rate over time

**16:00 - Deep Dive Consolidation**
- Docs: Documentar partition health metrics
- Criar recommendations para optimization
- Validar: Todas partiÃ§Ãµes <5 hits por query?

**17:00 - Evening Status**
- Status: RPC capacity + Auto-partition stress OK?
- Partition efficiency dentro de expectativa?
- Ready para Day 4 (resource estimation)?

---

### ğŸ“ˆ Dia 4: FEB 10 - Resource Estimation + Production Sizing + Sign-off

**Objetivo:** Finalizar anÃ¡lise e gerar sign-off de produÃ§Ã£o

#### ManhÃ£ (09:00-12:00 UTC)

**09:00 - Daily Sync #4 (FINAL)**
- All results from Days 1-3 coletados?
- Resource estimation team briefing
- Sign-off criteria review

**10:00 - Resource Estimation (CPU, Memory, Storage, Network)**

Docs + Agent-DB calculam recursos para 3 cenÃ¡rios:

**CenÃ¡rio SMALL (100 usuÃ¡rios simultÃ¢neos, 251 GIS features)**
- CPU requirement:
  - Baseline (sem OPT): 2 vCPU
  - Com OPT1-5: 1 vCPU (50% reduÃ§Ã£o esperada)
  - Margem de seguranÃ§a: +1 vCPU overhead â†’ 2 vCPU final
- Memory requirement:
  - Baseline buffers/cache: 4 GB
  - Com OPT2 (columnar) + indexes: +2 GB
  - Com OPT5 (MV materialization): +1 GB
  - Final: 7 GB RAM
- Storage:
  - Baseline: 10 GB
  - CompressÃ£o OPT2: -60% â†’ 4 GB
  - Indexes overhead: +1 GB
  - Final: 5 GB storage
- Network:
  - Baseline throughput: 100 Mbps
  - Com RPC optimization (OPT3): reuse connections
  - Estimated BW: 50 Mbps (50% reduÃ§Ã£o)

**CenÃ¡rio MEDIUM (500 usuÃ¡rios simultÃ¢neos)**
- CPU: 4 vCPU
- Memory: 16 GB
- Storage: 12 GB
- Network: 200 Mbps

**CenÃ¡rio LARGE (1000+ usuÃ¡rios simultÃ¢neos)**
- CPU: 8 vCPU
- Memory: 32 GB
- Storage: 25 GB
- Network: 400 Mbps

**Cost Estimation (Annual):**
- SMALL: ~$500/month = $6,000/year
- MEDIUM: ~$1,500/month = $18,000/year
- LARGE: ~$3,500/month = $42,000/year

#### Tarde (12:00-17:00 UTC)

**13:00 - Production Readiness Review**

Checklist de conformidade para sign-off:

| Eixo | MÃ©trica | Status | Threshold | Result |
|------|---------|--------|-----------|--------|
| 1 | Query latency improvement | â³ | >30% vs baseline | ? |
| 1 | Throughput improvement | â³ | >25% vs baseline | ? |
| 1 | P95 latency reduction | â³ | >35% vs baseline | ? |
| 2 | Partition pruning hit rate | â³ | >95% | ? |
| 2 | Queries <5 partition scans | â³ | 100% compliance | ? |
| 2 | Index efficiency | â³ | >90% hit rate | ? |
| 3 | MV refresh time | â³ | <5 minutes | ? |
| 3 | Refresh CPU overhead | â³ | <5% peak impact | ? |
| 4 | RPC P95 latency | â³ | <200ms (1000 concurrent) | ? |
| 4 | RPC throughput | â³ | >50 RPC/s | ? |
| 5 | Auto-partition overhead | â³ | <2% CPU during trigger | ? |
| 6 | Resource sizing | â³ | 3 scenarios documented | ? |

**14:00 - Final Documentation & Audit Trail**

Docs team compila final documentation:
- METRICS_STAGE4_FINAL.json (todos os nÃºmeros)
- GRAFANA_DASHBOARDS_STAGE4.json (export de todos os dashboards)
- RESOURCE_MATRIX_SCENARIOS.md (sizing para S/M/L)
- PARTITION_HEALTH_REPORT.md (deep dive anÃ¡lise)
- RPC_LOAD_TEST_RESULTS.md (capacity findings)
- AUTO_PARTITION_STRESS_REPORT.md (2029+ simulation)

**15:00 - Go/No-Go Decision**

Executor/Orquestrador convoca sign-off committee:

**PASS Criteria (Go para ProduÃ§Ã£o):**
- âœ… 6 eixos: 5+ de 6 com 100% success criteria
- âœ… Nenhum blocker crÃ­tico nÃ£o-mitigado
- âœ… DocumentaÃ§Ã£o completa para auditoria
- âœ… Rollback plan validado (STAGE 3)

**FAIL Criteria (No-Go / RevisÃ£o):**
- âŒ Qualquer eixo com <80% success criteria
- âŒ RPC nÃ£o passa load test (P95 >200ms ou error rate >0%)
- âŒ Auto-partition overhead >2%
- âŒ Resource estimation discrepÃ¢ncias >20%

**15:30 - Sign-off Formal**

Documento assinado:
- **STAGE_4_CAPACITY_PLANNING_SIGNOFF.md**
  - Resultado de cada eixo
  - Go/No-Go decision + reasoning
  - MitigaÃ§Ãµes de qualquer blocker
  - RecomendaÃ§Ãµes para STAGE 5 (ProduÃ§Ã£o)

**16:00 - Handoff para STAGE 5**
- Docs: Entregar documentaÃ§Ã£o para Ã©quipe de produÃ§Ã£o
- Agent-DB: Prepare rollback scripts (se No-Go)
- Executor: Schedule STAGE 5 kickoff (se Go)

**17:00 - FINAL Status**
- Fim de STAGE 4
- Resultado final documentado

---

## ğŸ¯ EIXO 1: Benchmark Performance das 5 OtimizaÃ§Ãµes (OPT1-OPT5)

### DescriÃ§Ã£o

Quantificar ganhos de performance de cada otimizaÃ§Ã£o individual (OPT1 a OPT5) atravÃ©s de benchmarking comparativo:
- Baseline (sem otimizaÃ§Ãµes) vs cada OPT aplicada isoladamente
- Dataset: 251 GIS features com 100+ query patterns representativos
- Resultado: Tabela de improvements % com P50/P95/P99 latency breakdown

### MÃ©tricas Detalhadas

| MÃ©trica | DescriÃ§Ã£o | Unidade | Target | Owner |
|---------|-----------|---------|--------|-------|
| **Query Latency (P50)** | Mediana de tempo de resposta | ms | >30% reduction | Agent-DB |
| **Query Latency (P95)** | 95Âº percentil (tail latency) | ms | >35% reduction | Agent-DB |
| **Query Latency (P99)** | 99Âº percentil | ms | >40% reduction | Agent-DB |
| **Throughput (QPS)** | Queries por segundo sustentÃ¡vel | QPS | +25% vs baseline | Agent-DB |
| **CPU Utilization** | CPU durante teste | % | <80% durante test | Observability |
| **Memory Usage** | RAM consumida | MB | baseline +10-20% acceptable | Observability |
| **Disk IO (IOPS)** | I/O operations | IOPS | 50% reduction vs baseline | Agent-DB |

### Ferramentas & Procedimentos

**Ferramentas:**
- **Grafana + Prometheus:** Dashboards de mÃ©tricas em tempo real
- **PostgreSQL EXPLAIN ANALYZE:** Para validar execution plans
- **Apache JMeter/pgBench:** Load testing tools
- **Custom script (python):** Para orquestrar testes paralelos

**Procedimento Dia 2:**

```
T+0 min: Disable OPT1-5 (rollback para baseline)
T+5 min: Executar 100 queries (baseline) â†’ Coletar P50/P95/P99
T+15 min: Enable OPT1 (temporal partitioning)
T+20 min: Executar mesmas 100 queries com OPT1 ativa
T+25 min: Comparar resultados, calcular % improvement
...
T+90 min: Todos OPT1-5 testados, resultados compilados
```

### Success Criteria

| CritÃ©rio | MÃ©trica | Limiar | Status |
|----------|---------|--------|--------|
| **Performance baseline** | Latency P95 coletada | >0 ms | âœ“ |
| **OPT1 improvement** | Latency reduÃ§Ã£o | >30% | ? |
| **OPT2 improvement** | Throughput aumento | >20% | ? |
| **OPT3 improvement** | Search latency | >50% | ? |
| **OPT4 nÃ£o regride** | Insert latency overhead | <2% | ? |
| **OPT5 nÃ£o regride** | Refresh impact | <5% CPU | ? |

### Blocker Risks & Mitigation

| Risk | Probabilidade | Impacto | Mitigation |
|------|--------------|--------|-----------|
| Queries nÃ£o usam OPT indexes | MÃ‰DIA | ALTO | Rewrite queries para forÃ§ar index usage |
| Dataset insuficiente (<251) | BAIXA | MÃ‰DIO | Populat dados faltantes em Dia 1 |
| MÃ©trica coleta falha | BAIXA | MÃ‰DIO | Validar Prometheus setup no kickoff |
| OPT performance regride | BAIXA | CRÃTICO | Escalate para Agent-DB, revisar SQL |

### Dono da ExecuÃ§Ã£o

**Agent-DB** (com suporte Observability para Grafana)

### Documento Output Esperado

- `METRICS_OPT1_OPT5_COMPARISON_FEB8.md`
- Tabela comparativa: Baseline vs OPT1-5 (todas mÃ©tricas)
- GrÃ¡ficos latency por percentil (Grafana snapshot)
- RecomendaÃ§Ãµes de combinaÃ§Ãµes OPT que mais performam

---

## ğŸ¯ EIXO 2: AnÃ¡lise de Partitioning Efficiency (OPT1 + OPT4)

### DescriÃ§Ã£o

Validar que particionamento temporal (OPT1) + auto-partition (OPT4) estÃ¡ funcionando otimalmente:
- Cobertura de partiÃ§Ãµes: % de queries aproveitando partition pruning
- Partition scan efficiency: MÃ©dia de partiÃ§Ãµes scannadas por query (target <5)
- Ãndices GIST funcionando corretamente em cada partiÃ§Ã£o

### MÃ©tricas Detalhadas

| MÃ©trica | DescriÃ§Ã£o | Unidade | Target | Owner |
|---------|-----------|---------|--------|-------|
| **Partition Pruning Hit Rate** | % queries usando partition pruning | % | >95% | Agent-DB |
| **Avg Partitions per Query** | MÃ©dia de partiÃ§Ãµes scannadas | count | <5 | Agent-DB |
| **Index Hit Rate** | % de index scans vs seq scans | % | >90% | Agent-DB |
| **Partition Distribution** | Data uniformidade nos years | % | 30-40% cada | Agent-DB |
| **Scan Coverage** | % de data scannada efetivamente | % | <20% vs without partitions | Agent-DB |

### Ferramentas & Procedimentos

**Ferramentas:**
- **PostgreSQL EXPLAIN ANALYZE:** Para validar partition pruning nas execution plans
- **pg_stat_statements:** Para track partition usage stats
- **Grafana:** Dashboard de partition health
- **Custom query analyzer:** Script Python para parse 20 queries crÃ­ticas

**Procedimento Dia 3:**

```
Parte 1: EXPLAIN ANALYZE de 20 queries crÃ­ticas
  T+0: Para cada query, gerar EXPLAIN (JSON output)
  T+5: Parse execution plan, extract partition count
  T+10: Validate partition pruning is happening

Parte 2: Dashboard de partition health
  T+15: Criar Grafana dashboard com:
    - Partition size distribution (pie chart)
    - Query scan patterns (histogram)
    - Index usage by partition (bar chart)
    - Pruning hit rate trends (line chart)

Parte 3: Auto-partition (OPT4) validation
  T+45: Simulate 2029 data â†’ trigger auto-create
  T+50: Verify new partition + indexes criados
  T+55: EXPLAIN queries com 2029 data â†’ hit rate OK?
```

### Success Criteria

| CritÃ©rio | MÃ©trica | Limiar | Status |
|----------|---------|--------|--------|
| **Pruning habilitado** | Hit rate | >95% | ? |
| **Scans eficientes** | Avg partitions | <5 | ? |
| **Ãndices usados** | Hit rate GIST | >90% | ? |
| **DistribuiÃ§Ã£o uniforme** | Year distribution | 30-40% | ? |
| **Auto-partition OK** | 2029 partiÃ§Ã£o criada | âœ“ | ? |

### Blocker Risks & Mitigation

| Risk | Probabilidade | Impacto | Mitigation |
|------|--------------|--------|-----------|
| Queries nÃ£o usam partition pruning | MÃ‰DIA | ALTO | Rewrite query WHERE clauses |
| Partition imbalance (1 year >80%) | BAIXA | MÃ‰DIO | Reparticionar dados historicamente |
| Index GIST nÃ£o criado auto | BAIXA | MÃ‰DIO | Manual index creation em 2029 partition |
| Auto-partition trigger falha | BAIXA | CRÃTICO | Escalate, revisar trigger function |

### Dono da ExecuÃ§Ã£o

**Agent-DB** (com suporte Observability para Grafana)

### Documento Output Esperado

- `PARTITION_HEALTH_REPORT_FEB9.md`
- Tabela EXPLAIN ANALYZE para 20 queries (com partition count)
- Grafana dashboard snapshot (partition metrics)
- RecomendaÃ§Ãµes de tuning (se hits <95%)

---

## ğŸ¯ EIXO 3: MV Refresh Performance (OPT5)

### DescriÃ§Ã£o

Validar que scheduled materialized views (OPT5 + pg_cron) performam dentro de limites:
- Refresh time <5 minutos para o stack completo
- CPU overhead <5% durante refresh em contexto de queries concorrentes
- Cron scheduling accuracy (jobs executam no hora certa)

### MÃ©tricas Detalhadas

| MÃ©trica | DescriÃ§Ã£o | Unidade | Target | Owner |
|---------|-----------|---------|--------|-------|
| **Full Refresh Time** | Tempo refresh all MVs | min | <5 min | Cache |
| **CPU Peak During Refresh** | CPU utilization pico | % | <20% peak | Observability |
| **Memory During Refresh** | RAM needed | MB | baseline +500 MB max | Observability |
| **Query Impact** | Latency increase queries concorrentes | % | <5% | Cache |
| **Cron Accuracy** | Job execution on-schedule | % | 100% | Observability |
| **Refresh Failure Rate** | % failed refreshes | % | 0% | Cache |

### Ferramentas & Procedimentos

**Ferramentas:**
- **pg_cron:** Built-in PostgreSQL task scheduler
- **PostgreSQL logs:** Para track refresh job execution
- **Grafana:** Monitor CPU/Memory durante refresh
- **Custom monitor script:** Track mv_refresh_log table

**Procedimento Dia 3:**

```
T+0 min: Setup monitoring (Grafana CPU/Memory gauges)
T+5 min: Disable auto cron jobs (manual test only)
T+10 min: Execute refresh_all_materialized_views() manualmente
T+15 min: Monitor:
  - Time to completion
  - Peak CPU (target <20%)
  - Peak Memory
  - Any query errors?
T+20 min: Check mv_refresh_log table (should show job completed)

T+25 min: Enable cron jobs
T+30 min: Monitor cron execution (3 jobs running):
  - refresh-mv-stats-hourly (0 * * * *)
  - refresh-mv-search-30min (*/30 * * * *)
  - refresh-mv-full-night (0 2 * * *)
  
T+60 min: Review logs de 3 execuÃ§Ãµes (should be 100% success)

T+90 min: Stress test - verificar impact em queries concorrentes
  - Start: Load test (100 QPS parallel queries)
  - Trigger: Manual refresh_all_materialized_views()
  - Measure: Latency increase during refresh
  - Target: <5% impact
```

### Success Criteria

| CritÃ©rio | MÃ©trica | Limiar | Status |
|----------|---------|--------|--------|
| **Refresh time OK** | Full refresh | <5 min | ? |
| **CPU aceitÃ¡vel** | Peak durante refresh | <20% | ? |
| **Memory OK** | Peak durante refresh | baseline +500 MB | ? |
| **Query impact minimal** | Latency increase | <5% | ? |
| **Cron acurado** | Execution on-schedule | 100% | ? |
| **Sem falhas** | Failure rate | 0% | ? |

### Blocker Risks & Mitigation

| Risk | Probabilidade | Impacto | Mitigation |
|------|--------------|--------|-----------|
| Refresh time >5 min | MÃ‰DIA | ALTO | Otimizar MV definition (menos dados), split em 2 MVs |
| CPU overhead >5% | BAIXA | MÃ‰DIO | Reschedule refresh para off-peak hours |
| Cron jobs nÃ£o executando | BAIXA | CRÃTICO | Check pg_cron extension installed, check logs |
| Query latency degradation | BAIXA | MÃ‰DIO | Increase READ replica capacity, or reschedule refresh |

### Dono da ExecuÃ§Ã£o

**Cache** (com suporte Agent-DB + Observability)

### Documento Output Esperado

- `MV_REFRESH_PERFORMANCE_REPORT_FEB9.md`
- Tabela: Refresh times + CPU/Memory metrics
- Cron job execution log (3 cron jobs, 100% success)
- RecomendaÃ§Ãµes de schedule otimizado (se preciso ajustar)

---

## ğŸ¯ EIXO 4: RPC Search Performance (OPT3)

### DescriÃ§Ã£o

Validar que indexed views + RPC search (OPT3) performam sob carga:
- 1000 RPC calls simultÃ¢neas: P95 <200ms, P99 <500ms
- Throughput >50 RPC/s sustentÃ¡vel
- 0% error rate
- Capacity estimation: Quantos usuÃ¡rios simultÃ¢neos suportados

### MÃ©tricas Detalhadas

| MÃ©trica | DescriÃ§Ã£o | Unidade | Target | Owner |
|---------|-----------|---------|--------|--------|
| **RPC P95 Latency (1000 conc)** | 95Âº percentil resposta | ms | <200 ms | Cache |
| **RPC P99 Latency (1000 conc)** | 99Âº percentil resposta | ms | <500 ms | Cache |
| **Throughput (1000 conc)** | RPC calls/second | RPC/s | >50 RPC/s | Cache |
| **Error Rate (1000 conc)** | % failed calls | % | 0% | Cache |
| **Connection Pool Stress** | Max connections needed | count | <100 | Observability |
| **CPU During Load** | CPU utilization | % | <80% | Observability |
| **Breaking Point** | Max concurrent before 3x degradation | count | >1000 | Cache |

### Ferramentas & Procedimentos

**Ferramentas:**
- **Apache JMeter / Locust:** Load testing framework
- **Grafana:** Real-time latency/throughput monitoring
- **PostgreSQL connection stats:** pg_stat_activity
- **Custom load script:** Python/Node.js RPC client

**Procedimento Dia 3:**

```
T+0 min: Setup load test environment
  - JMeter configured with 1000 thread pool
  - Grafana dashboard live (latency, throughput, errors)
  - Database connection monitoring enabled

T+5 min: Warmup phase (100 concurrent, 2 min)
  - Establish connections
  - Cache initialization
  - Verify no errors

T+10 min: LOAD TEST PHASE 1 (1000 concurrent, 5 min)
  - Ramp up: 200 threads/min
  - Run 1000 threads in parallel
  - All threads issue mix of RPC queries:
    - search_catalogo_indexed(texto, tipo, geometric, limit, offset)
    - Variations: 50% bounds queries, 30% full-text, 20% filtered

T+15 min: Continuous monitoring
  - P95 latency (live graph)
  - Throughput (RPC/s)
  - Error rate
  - CPU on database
  - Connection count

T+20 min: Collect results
  - Raw latency histogram
  - Percentile breakdown (P50/P95/P99)
  - Throughput statistics
  - Error breakdown (if any)

T+25 min: STRESS TEST PHASE 2 (2000 concurrent, 3 min)
  - Double the load (2000 threads)
  - Measure: How much does performance degrade?
  - Target: P95 should go to <600ms (3x), not worse
  - Identify: Where does system break (error rate >5%)?

T+30 min: Cool down & recovery
  - Drop to 0 concurrent
  - Monitor: DB recovers to idle state?
  - No lingering connections?

T+35 min: Results consolidation
  - Parse JMeter results
  - Generate Grafana screenshot
  - Capacity calculation
```

### Success Criteria

| CritÃ©rio | MÃ©trica | Limiar | Status |
|----------|---------|--------|--------|
| **P95 latency OK** | 1000 concurrent | <200 ms | ? |
| **P99 latency OK** | 1000 concurrent | <500 ms | ? |
| **Throughput OK** | 1000 concurrent | >50 RPC/s | ? |
| **Error rate OK** | 1000 concurrent | 0% | ? |
| **Breaking point aceitÃ¡vel** | 2000 concurrent | P95 <3x vs 1000 | ? |
| **Connection pool OK** | Max connections | <100 | ? |

### Blocker Risks & Mitigation

| Risk | Probabilidade | Impacto | Mitigation |
|------|--------------|--------|-----------|
| P95 latency >200ms sob carga | MÃ‰DIA | ALTO | Add read replicas, cache at application layer |
| Error rate >0% | BAIXA | CRÃTICO | Debug connection issues, reschedule load test |
| Connection pool overflow | BAIXA | MÃ‰DIO | Increase PgBouncer pool size |
| CPU saturation | BAIXA | MÃ‰DIO | Upgrade to larger database instance |

### Dono da ExecuÃ§Ã£o

**Cache** (com suporte Agent-DB + Observability)

### Documento Output Esperado

- `RPC_LOAD_TEST_RESULTS_FEB9.md`
- Tabela latency percentiles (P50/P95/P99) para 1000 e 2000 concurrent
- Grafana screenshot (latency, throughput, CPU live)
- Capacity calculation: N usuÃ¡rios simultÃ¢neos suportados
- RecomendaÃ§Ãµes de connection pool + scaling

---

## ğŸ¯ EIXO 5: Auto-Partition Overhead (OPT4)

### DescriÃ§Ã£o

Validar que auto-partition trigger (OPT4) nÃ£o causa overhead significativo:
- Overhead na operaÃ§Ã£o INSERT <2% vs sem trigger
- Trigger executa sem lock contention
- Auto-criaÃ§Ã£o de Ã­ndices funciona e nÃ£o causa INSERT slowdown
- Teste simulando crescimento 2029+ (quando trigger serÃ¡ ativado)

### MÃ©tricas Detalhadas

| MÃ©trica | DescriÃ§Ã£o | Unidade | Target | Owner |
|---------|-----------|---------|--------|--------|
| **INSERT Latency Overhead** | Slowdown due to trigger | % | <2% | Agent-DB |
| **Trigger Execution Time** | Time per trigger invocation | ms | <10 ms | Agent-DB |
| **Index Creation Time** | Auto-index para novo year | sec | <5 sec | Agent-DB |
| **Lock Contention** | Waits during trigger | count | 0 | Agent-DB |
| **CPU Peak** | CPU during trigger | % | <10% | Observability |
| **Memory Usage** | RAM during trigger | MB | baseline +50 MB | Observability |

### Ferramentas & Procedimentos

**Ferramentas:**
- **PostgreSQL pg_stat_locks:** Monitor lock contention
- **Custom insert script:** Parallel INSERT test
- **EXPLAIN ANALYZE:** Validate trigger execution path
- **Grafana:** CPU/Memory monitoring

**Procedimento Dia 3:**

```
PARTE 1: Baseline (Sem OPT4 - sem trigger)
T+0 min: Disable trigger auto_create_partition_for_year
T+5 min: Execute 10,000 INSERT statements (test year 2028)
  - Measure: Average INSERT latency
  - Target: <5ms per INSERT
  - Store as BASELINE_INSERT_LATENCY

PARTE 2: Com OPT4 (com trigger ativo)
T+10 min: Enable trigger
T+15 min: Execute 10,000 INSERT statements (test year 2028 - existing partition)
  - Measure: Average INSERT latency (trigger still checks if partition exists)
  - Target: <5.1ms (max 2% overhead)
  - Calculate: (latency_with_trigger / baseline) * 100

PARTE 3: Trigger Activation (Novo year 2029)
T+20 min: Execute INSERT com created_at = 2029-01-01
  - First INSERT triggers: create_missing_year_partitions()
  - Measure:
    - Trigger execution time
    - Index creation time (GIST + composite)
    - Lock contention (pg_locks)
    - CPU peak

T+25 min: Continue 2029 INSERTs (partition now exists)
  - Verify: Overhead volta a <2%

PARTE 4: Stress (Simulando 2029+ growth)
T+30 min: Parallel load test
  - 100 concurrent INSERTs to various 2029-2035 years
  - First INSERT per year triggers auto-create
  - Monitor:
    - Overall throughput (INSERTs/sec)
    - Lock contention
    - CPU/Memory peaks
    - Any failed INSERTs?
  - Target: No errors, overhead <2%
```

### Success Criteria

| CritÃ©rio | MÃ©trica | Limiar | Status |
|----------|---------|--------|--------|
| **INSERT overhead minimal** | vs baseline | <2% | ? |
| **Trigger fast** | Per invocation | <10 ms | ? |
| **Index creation fast** | Per new year | <5 sec | ? |
| **Sem lock contention** | pg_locks waits | 0 | ? |
| **CPU aceitÃ¡vel** | Peak durante trigger | <10% | ? |
| **Stress test OK** | 100 concurrent 2029+ | 0 errors | ? |

### Blocker Risks & Mitigation

| Risk | Probabilidade | Impacto | Mitigation |
|------|--------------|--------|-----------|
| Trigger overhead >2% | BAIXA | MÃ‰DIO | Optimize function logic, consider partial indexes |
| Index creation locks writes | BAIXA | CRÃTICO | Use CONCURRENTLY index creation, retry logic |
| Lock contention detected | MUITO BAIXA | CRÃTICO | Escalate, redesign trigger |
| Trigger fails for 2029+ | MUITO BAIXA | CRÃTICO | Manual partition + index creation, disable trigger |

### Dono da ExecuÃ§Ã£o

**Agent-DB** (com suporte Observability)

### Documento Output Esperado

- `AUTO_PARTITION_STRESS_REPORT_FEB9.md`
- Tabela: Baseline vs com trigger (latency comparison)
- Trigger execution metrics (invocations, timing)
- Index creation log (2029-2035 partitions created)
- CPU/Memory graphs (Grafana snapshot)
- RecomendaÃ§Ãµes (se overhead >2%, otimizations)

---

## ğŸ¯ EIXO 6: Estimativa de Recursos para ProduÃ§Ã£o

### DescriÃ§Ã£o

Consolidar todos os learnings dos Eixos 1-5 para estimar CPU/Memory/Storage/Network necessÃ¡rios em produÃ§Ã£o, para 3 cenÃ¡rios de escala (Small/Medium/Large).

### MÃ©tricas Detalhadas

| MÃ©trica | DescriÃ§Ã£o | Unidade | SMALL | MEDIUM | LARGE |
|---------|-----------|---------|-------|--------|-------|
| **CPU Cores** | vCPU needed | cores | 2 | 4 | 8 |
| **Memory** | RAM allocation | GB | 7 | 16 | 32 |
| **Storage** | Disk space | GB | 5 | 12 | 25 |
| **Network BW** | Peak bandwidth | Mbps | 50 | 200 | 400 |
| **Concurrent Users** | Simultaneous capacity | users | 100 | 500 | 1000+ |
| **Monthly Cost** | Cloud cost estimate | $/mo | ~$500 | ~$1,500 | ~$3,500 |

### CÃ¡lculo por CenÃ¡rio

#### **CenÃ¡rio SMALL: 100 UsuÃ¡rios SimultÃ¢neos, 251 GIS Features**

**CPU Calculation:**
- Baseline (sem OPT): 2 vCPU needed para 100 concurrent
- Com OPT1-5: 50% reduction esperado â†’ 1 vCPU
- Margem de seguranÃ§a: +1 vCPU
- **Final: 2 vCPU**

**Memory Calculation:**
- PostgreSQL shared_buffers: 2 GB
- Working memory (work_mem Ã— max_parallel): 1 GB
- OPT2 columnar cache (mv + bounds): 2 GB
- OPT5 materialized views: 1 GB
- OS + overhead: 1 GB
- **Final: 7 GB RAM**

**Storage Calculation:**
- Base GIS data: 10 GB
- OPT2 columnar compression: -60% â†’ 4 GB
- Indexes (GIST, composite, full-text): +1 GB
- WAL logs + checkpoints: 500 MB
- **Final: 5 GB**

**Network Calculation:**
- RPC query BW: 100 Mbps baseline
- With OPT3 (connection reuse): 50% reduction
- **Final: 50 Mbps peak**

**Cost (AWS/GCP/Azure 2026 pricing):**
- 2 vCPU = ~$50/month
- 7 GB RAM = ~$150/month
- 5 GB storage = ~$1/month
- Network = ~$300/month (est.)
- **Total: ~$500/month = $6,000/year**

#### **CenÃ¡rio MEDIUM: 500 UsuÃ¡rios SimultÃ¢neos**

Baseline â†’ x5 escalation vs SMALL

- **CPU: 4 vCPU** (SMALL 2 Ã— 2.5, minus 10% efficiency gain via OPT)
- **Memory: 16 GB** (SMALL 7 Ã— 2, plus 2 GB cache growth)
- **Storage: 12 GB** (SMALL 5 Ã— 2.4, data growth)
- **Network: 200 Mbps** (peak, sustained ~100 Mbps)
- **Cost: ~$1,500/month = $18,000/year**

#### **CenÃ¡rio LARGE: 1000+ UsuÃ¡rios SimultÃ¢neos**

Baseline â†’ x10 escalation vs SMALL

- **CPU: 8 vCPU** (SMALL 2 Ã— 4.5, with efficiency from OPT)
- **Memory: 32 GB** (SMALL 7 Ã— 4.5, cache + buffers)
- **Storage: 25 GB** (SMALL 5 Ã— 5, compounded growth)
- **Network: 400 Mbps** (peak, sustained ~200 Mbps)
- **Cost: ~$3,500/month = $42,000/year**

### Ferramentas & Procedimentos

**Procedimento Dia 4:**

```
T+0 min: Consolidate all Eixo 1-5 metrics
  - Query latency improvement: % reduction
  - Partition scan efficiency: avg partitions per query
  - MV refresh overhead: % CPU impact
  - RPC capacity: N concurrent at P95 <200ms
  - Auto-partition overhead: % INSERT slowdown

T+10 min: Build resource matrix
  - For each scenario (S/M/L):
    - Calculate CPU from throughput (QPS at target P95)
    - Calculate Memory from indexes + cache size
    - Calculate Storage from data compression
    - Calculate Network from RPC BW + replication

T+30 min: Cost estimation
  - Research cloud pricing (AWS/GCP/Azure)
  - Calculate monthly cost per scenario
  - Annualize (Ã—12 months)

T+45 min: Sensitivity analysis
  - What if OPT doesn't deliver 50% improvement?
  - What if user growth is 2x faster?
  - What if storage compression is only 40% not 60%?
  - Risk matrix: best/expected/worst case costs

T+60 min: Recommendations
  - For each scenario: Recommended instance types (AWS/GCP)
  - Recommended read replicas
  - Recommended backup strategy
  - Migration path (S â†’ M â†’ L)
```

### Success Criteria

| CritÃ©rio | MÃ©trica | Limiar | Status |
|----------|---------|--------|--------|
| **S sizing OK** | 100 users capacity | âœ“ | ? |
| **M sizing OK** | 500 users capacity | âœ“ | ? |
| **L sizing OK** | 1000+ users capacity | âœ“ | ? |
| **Cost realistic** | Cloud pricing accuracy | Â±20% | ? |
| **Sensitivity analysis** | Risk scenarios documented | all 3 covered | ? |

### Blocker Risks & Mitigation

| Risk | Probabilidade | Impacto | Mitigation |
|------|--------------|--------|-----------|
| OPT doesn't achieve 50% improvement | MÃ‰DIA | ALTO | Recalculate with observed actual improvement |
| Cloud pricing changed | BAIXA | MÃ‰DIO | Use multiple cloud vendors, estimate range |
| User growth faster than expected | BAIXA | MÃ‰DIO | Design for L scenario upfront, plan upgrade path |
| Storage compression less than 60% | MÃ‰DIA | MÃ‰DIO | Recalculate with 40% compression, budget more storage |

### Dono da ExecuÃ§Ã£o

**Docs** (com suporte Agent-DB + Observability)

### Documento Output Esperado

- `RESOURCE_MATRIX_SCENARIOS_FEB10.md`
- Tabela detailed: CPU/Memory/Storage/Network/Cost para S/M/L
- JustificaÃ§Ã£o de cada nÃºmero (baseado em Eixo 1-5 results)
- Sensitivity analysis (best/expected/worst case)
- Recommended cloud instance types (AWS t3/m5, GCP n1/n2, Azure B/D)
- Migration path (how to scale from S â†’ M â†’ L)

---

## ğŸ”— INTEGRATION POINTS

### Daily Synchronization

#### **Daily Sync #1 - FEB 7, 09:00 UTC (Kickoff)**
- **DuraÃ§Ã£o:** 30 min
- **Attendees:** Agent-DB, Cache, Observability, Docs, Executor/Orquestrador
- **Agenda:**
  - Ambiente setup validation (Grafana, Prometheus, dataset)
  - Role assignment confirmation
  - Baseline collection status
  - Blockers? Escalation needed?

#### **Daily Sync #2 - FEB 8, 09:00 UTC (Day 2)**
- **DuraÃ§Ã£o:** 30 min
- **Agenda:**
  - Baseline collection: Complete? 6 mÃ©tricas OK?
  - OPT1-5 test execution status
  - Preliminary results (if ready)
  - Adjustments needed for Day 3?

#### **Daily Sync #3 - FEB 9, 09:00 UTC (Day 3)**
- **DuraÃ§Ã£o:** 30 min
- **Agenda:**
  - OPT1-5 results review
  - RPC load test + Auto-partition stress prep
  - Resource estimation timeline
  - Any metric validation issues?

#### **Daily Sync #4 - FEB 10, 09:00 UTC (Sign-off Day)**
- **DuraÃ§Ã£o:** 30 min
- **Agenda:**
  - All results consolidated?
  - Resource matrix final numbers
  - Sign-off gate review (6 eixos OK?)
  - Go/No-Go decision date/time

### Daily Checkpoints

#### **Morning Standups - 09:00 UTC Cada Dia**
- 30 min: Daily sync (acima)
- Each agent: 3 min status (completed, blockers, next 24h plan)

#### **Evening Status Reports - 17:00 UTC Cada Dia**
- 30 min: Executor/Orquestrador convoca
- Metrics collected: Yes/No/Partial
- Blocker escalation: Any L1/L2/L3 needed?
- Readiness para prÃ³ximo dia

### Escalation Policy

#### **Level 1 (Agente-to-Executor):**
- Trigger: Test failure, metric invalid, environment issue
- Response time: <1 hour
- Resolution: Executor coordinates fix, retry test

#### **Level 2 (Executor-to-Orquestrador):**
- Trigger: Test cannot recover, resource unavailable, timeline risk
- Response time: <2 hours
- Resolution: Orquestrador allocates resources, rescopes if needed

#### **Level 3 (Orquestrador-to-Decision Gate):**
- Trigger: Go/No-Go gate at risk, critical metric missing, architecture issue
- Response time: <4 hours
- Resolution: Executive sign-off, decision on continuation or pivot

---

## âœ… SIGN-OFF GATE (FEB 10, 15:00 UTC)

### Checklist de Conformidade (6 Eixos)

Todos os itens devem ser âœ… PASS para Go decisiÃ³n:

#### **Eixo 1: Benchmark Performance OPT1-OPT5**

| Item | MÃ©trica | Threshold | Status |
|------|---------|-----------|--------|
| Baseline coletado | 6 mÃ©tricas P50/P95/P99 | âœ“ | â³ |
| OPT1 improvement | Query latency P95 | >30% reduction | â³ |
| OPT2 improvement | Throughput | >20% increase | â³ |
| OPT3 improvement | Search latency | >50% reduction | â³ |
| OPT4 nÃ£o regride | INSERT overhead | <2% | â³ |
| OPT5 nÃ£o regride | Refresh CPU impact | <5% | â³ |
| **Eixo 1 Status** | **Pass/Fail** | **5/6 = Pass** | â³ |

#### **Eixo 2: Partitioning Efficiency**

| Item | MÃ©trica | Threshold | Status |
|------|---------|-----------|--------|
| Pruning habilitado | Hit rate | >95% | â³ |
| Scans eficientes | Avg partitions per query | <5 | â³ |
| Ãndices usados | GIST hit rate | >90% | â³ |
| DistribuiÃ§Ã£o uniforme | Year distribution | 30-40% each | â³ |
| Auto-partition OK | 2029 partition created | âœ“ | â³ |
| **Eixo 2 Status** | **Pass/Fail** | **5/5 = Pass** | â³ |

#### **Eixo 3: MV Refresh Performance**

| Item | MÃ©trica | Threshold | Status |
|------|---------|-----------|--------|
| Refresh time OK | Full refresh | <5 min | â³ |
| CPU aceitÃ¡vel | Peak during refresh | <20% | â³ |
| Memory OK | Peak during refresh | baseline +500 MB | â³ |
| Query impact minimal | Latency increase | <5% | â³ |
| Cron acurado | Execution on-schedule | 100% | â³ |
| Sem falhas | Failure rate | 0% | â³ |
| **Eixo 3 Status** | **Pass/Fail** | **6/6 = Pass** | â³ |

#### **Eixo 4: RPC Search Performance**

| Item | MÃ©trica | Threshold | Status |
|------|---------|-----------|--------|
| P95 latency OK | 1000 concurrent | <200 ms | â³ |
| P99 latency OK | 1000 concurrent | <500 ms | â³ |
| Throughput OK | 1000 concurrent | >50 RPC/s | â³ |
| Error rate OK | 1000 concurrent | 0% | â³ |
| Breaking point acceptable | 2000 concurrent | P95 <3x degradation | â³ |
| Connection pool OK | Max connections | <100 | â³ |
| **Eixo 4 Status** | **Pass/Fail** | **6/6 = Pass** | â³ |

#### **Eixo 5: Auto-Partition Overhead**

| Item | MÃ©trica | Threshold | Status |
|------|---------|-----------|--------|
| INSERT overhead minimal | vs baseline | <2% | â³ |
| Trigger fast | Per invocation | <10 ms | â³ |
| Index creation fast | Per new year | <5 sec | â³ |
| Sem lock contention | pg_locks waits | 0 | â³ |
| CPU aceitÃ¡vel | Peak durante trigger | <10% | â³ |
| Stress test OK | 100 concurrent 2029+ | 0 errors | â³ |
| **Eixo 5 Status** | **Pass/Fail** | **6/6 = Pass** | â³ |

#### **Eixo 6: Resource Estimation**

| Item | MÃ©trica | Threshold | Status |
|------|---------|-----------|--------|
| SMALL scenario | 100 users, $6k/year | Documented | â³ |
| MEDIUM scenario | 500 users, $18k/year | Documented | â³ |
| LARGE scenario | 1000+ users, $42k/year | Documented | â³ |
| Sensitivity analysis | Best/Expected/Worst | Covered | â³ |
| Cloud pricing validated | AWS/GCP/Azure | Â±20% accuracy | â³ |
| Migration path | Sâ†’Mâ†’L scaling | Documented | â³ |
| **Eixo 6 Status** | **Pass/Fail** | **6/6 = Pass** | â³ |

---

### Go/No-Go Decision Criteria

#### **GO to Production** âœ…
Requer: **5/6 eixos com 100% pass** + nenhum blocker crÃ­tico nÃ£o-mitigado

Significado:
- OtimizaÃ§Ãµes performam conforme expectativa
- NÃ£o hÃ¡ surpresas de escalabilidade
- DocumentaÃ§Ã£o completa para rollback (STAGE 3 validado)
- Equipe confiante em produÃ§Ã£o

**AÃ§Ã£o:** Proceder para STAGE 5 (ProduÃ§Ã£o) com confianÃ§a

#### **NO-GO / RevisÃ£o** âŒ
Requer: **<5/6 eixos passando** OU **blocker crÃ­tico nÃ£o-mitigado**

Exemplos:
- RPC P95 latency >250ms (nÃ£o passa test)
- Auto-partition overhead >3% (unacceptable)
- Resource estimation discrepÃ¢ncias >30%
- Nenhuma mitigaÃ§Ã£o viÃ¡vel

**AÃ§Ã£o:** Escalate para Orquestrador, revisar architecture, reschedule STAGE 4

---

### Sign-off Document

Documento final: **`STAGE_4_CAPACITY_PLANNING_SIGNOFF.md`**

ContÃ©m:
1. **Executive summary:** Go/No-Go decision + reasoning
2. **Results table:** 6 eixos, mÃ©tricas finais, pass/fail
3. **Mitigations:** Qualquer blocker identificado + soluÃ§Ã£o
4. **Recommendations:** Para STAGE 5 produÃ§Ã£o
5. **Sign-offs:** Agent-DB, Cache, Observability, Docs, Executor/Orquestrador

---

## ğŸ“Š Diagrama de Fluxo - STAGE 4

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          STAGE 4: CAPACITY PLANNING (Feb 7-10)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

FEB 7 (Dia 1): SETUP + BASELINE
â”œâ”€â”€ 09:00 Kickoff sync
â”œâ”€â”€ 10:00 Baseline collection (sem OPT1-5)
â”‚   â”œâ”€â”€ Query latency (P50/P95/P99)
â”‚   â”œâ”€â”€ Throughput (QPS)
â”‚   â”œâ”€â”€ CPU/Memory/IO utilization
â”‚   â””â”€â”€ RPC baseline (100 calls)
â”œâ”€â”€ 14:00 MV + Auto-partition baseline
â”œâ”€â”€ 16:00 Consolidation: METRICS_BASELINE_FEB7.json
â””â”€â”€ 17:00 Evening status + Day 1 validation

FEB 8 (Dia 2): OPT BENCHMARKING
â”œâ”€â”€ 09:00 Sync #2
â”œâ”€â”€ 10:00 OPT1 + OPT2 tests (Agent-DB paralelo)
â”‚   â”œâ”€â”€ Temporal partitioning gains
â”‚   â””â”€â”€ Columnar storage compression
â”œâ”€â”€ 13:00 OPT3 + OPT4 + OPT5 tests
â”‚   â”œâ”€â”€ RPC search performance
â”‚   â”œâ”€â”€ Auto-partition overhead
â”‚   â””â”€â”€ MV refresh timing
â”œâ”€â”€ 16:00 Consolidation: METRICS_OPT1_OPT5_FEB8.md
â””â”€â”€ 17:00 Evening status + OPT results validation

FEB 9 (Dia 3): LOAD TESTS + DEEP DIVES
â”œâ”€â”€ 09:00 Sync #3
â”œâ”€â”€ 10:00 RPC Load Test (1000 concurrent)
â”‚   â”œâ”€â”€ P95/P99 latency validation
â”‚   â”œâ”€â”€ Throughput measurement
â”‚   â”œâ”€â”€ Stress test (2000 concurrent)
â”‚   â””â”€â”€ Capacity calculation
â”œâ”€â”€ 13:00 Auto-partition Stress (2029+)
â”‚   â”œâ”€â”€ INSERT overhead validation
â”‚   â”œâ”€â”€ Trigger execution metrics
â”‚   â””â”€â”€ Index creation timing
â”œâ”€â”€ 14:30 Partitioning Deep Dive
â”‚   â”œâ”€â”€ EXPLAIN ANALYZE (20 queries)
â”‚   â”œâ”€â”€ Partition pruning validation
â”‚   â””â”€â”€ Grafana dashboard creation
â”œâ”€â”€ 16:00 Consolidation: 3 reports (RPC, Auto-partition, Partition)
â””â”€â”€ 17:00 Evening status + Readiness for sign-off

FEB 10 (Dia 4): RESOURCE ESTIMATION + SIGN-OFF
â”œâ”€â”€ 09:00 Sync #4 (final)
â”œâ”€â”€ 10:00 Resource Estimation (S/M/L scenarios)
â”‚   â”œâ”€â”€ CPU/Memory/Storage/Network per scenario
â”‚   â”œâ”€â”€ Cost estimation (AWS/GCP/Azure)
â”‚   â”œâ”€â”€ Sensitivity analysis (best/expected/worst)
â”‚   â””â”€â”€ Migration path (Sâ†’Mâ†’L)
â”œâ”€â”€ 13:00 Production Readiness Review
â”‚   â”œâ”€â”€ Checklist validation (6 eixos)
â”‚   â”œâ”€â”€ Blocker assessment
â”‚   â””â”€â”€ Mitigation confirmation
â”œâ”€â”€ 15:00 Go/No-Go Decision
â”‚   â”œâ”€â”€ Committee review (5 agents + Executor)
â”‚   â”œâ”€â”€ Final approval
â”‚   â””â”€â”€ Sign-off document creation
â”œâ”€â”€ 16:00 Handoff to STAGE 5 (if Go)
â””â”€â”€ 17:00 STAGE 4 COMPLETE

Final Output Documents:
â”œâ”€â”€ METRICS_BASELINE_FEB7.json
â”œâ”€â”€ METRICS_OPT1_OPT5_COMPARISON_FEB8.md
â”œâ”€â”€ RPC_LOAD_TEST_RESULTS_FEB9.md
â”œâ”€â”€ AUTO_PARTITION_STRESS_REPORT_FEB9.md
â”œâ”€â”€ PARTITION_HEALTH_REPORT_FEB9.md
â”œâ”€â”€ MV_REFRESH_PERFORMANCE_REPORT_FEB9.md
â”œâ”€â”€ RESOURCE_MATRIX_SCENARIOS_FEB10.md
â””â”€â”€ STAGE_4_CAPACITY_PLANNING_SIGNOFF.md (Go/No-Go)
```

---

## ğŸ“ Resumo de EntregÃ¡veis

| Documento | Owner | Due | Status |
|-----------|-------|-----|--------|
| METRICS_BASELINE_FEB7.json | Observability | Feb 7 EOD | ğŸ”µ |
| METRICS_OPT1_OPT5_COMPARISON_FEB8.md | Agent-DB | Feb 8 EOD | ğŸ”µ |
| RPC_LOAD_TEST_RESULTS_FEB9.md | Cache | Feb 9 EOD | ğŸ”µ |
| AUTO_PARTITION_STRESS_REPORT_FEB9.md | Agent-DB | Feb 9 EOD | ğŸ”µ |
| PARTITION_HEALTH_REPORT_FEB9.md | Agent-DB | Feb 9 EOD | ğŸ”µ |
| MV_REFRESH_PERFORMANCE_REPORT_FEB9.md | Cache | Feb 9 EOD | ğŸ”µ |
| RESOURCE_MATRIX_SCENARIOS_FEB10.md | Docs | Feb 10 EOD | ğŸ”µ |
| STAGE_4_CAPACITY_PLANNING_SIGNOFF.md | Executor | Feb 10 15:00 | ğŸ”µ |

---

## ğŸ“Œ Notas Importantes

1. **Timeline CrÃ­tica:** 4 dias Ãºteis = 32 horas operacionais. Qualquer delay em Day 1-3 afeta Day 4 sign-off.

2. **DocumentaÃ§Ã£o para Auditoria:** Todos os resultados devem ser rastreÃ¡veis:
   - Query execution times com timestamps
   - Grafana dashboard snapshots
   - Database logs relevantes
   - Load test raw data (JMeter results)

3. **Fallback Plan:** Se qualquer eixo falhar:
   - Escalar para Orquestrador imediatamente
   - Considerar re-test ou ajustar scope
   - NÃ£o forÃ§ar sign-off com dados incompletos

4. **Continuidade de STAGE 3:** Rollback scripts (STAGE 3) devem estar prontos:
   - Se No-Go: execute rollbacks para reversÃ£o
   - Se Go: arquivar scripts para emergency-only

---

**Documento de Design Preparado para RevisÃ£o e AprovaÃ§Ã£o.**

Status: ğŸ”µ **EM DESIGN (Aguardando AprovaÃ§Ã£o do UsuÃ¡rio)**
